{"cells":[{"cell_type":"markdown","metadata":{"id":"SgsaPVBWAgsf"},"source":["# Загрузки и установка библиотек"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1704551593234,"user":{"displayName":"Andrey Petrunin","userId":"10287206466677589219"},"user_tz":-420},"id":"f7TVVj_z4flw","outputId":"5d5b3dd1-82f8-4ba9-a4f2-a88421ad812f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<audio src=\"https://oobabooga.github.io/silence.m4a\" controls>\n"]},"metadata":{}}],"source":["#@title 1. Keep this tab alive to prevent Colab from disconnecting you { display-mode: \"form\" }\n","\n","#@markdown Press play on the music player that will appear below:\n","%%html\n","<audio src=\"https://oobabooga.github.io/silence.m4a\" controls>"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1704551594364,"user":{"displayName":"Andrey Petrunin","userId":"10287206466677589219"},"user_tz":-420},"id":"FHfzYNeNABFk"},"outputs":[],"source":["import requests\n","\n","def load_file_content(url: str):\n","    response = requests.get(url) # Получение документа по url.\n","    response.raise_for_status()  # Проверка ответа и если была ошибка - формирование исключения.\n","    return response.content\n","\n","def download_file_from_url(url, save_path):\n","    content= load_file_content(url)\n","    with open(save_path, 'wb') as f:\n","        f.write(content)\n","        print(f\"File downloaded and saved as {save_path}\")\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":832,"status":"ok","timestamp":1704551601634,"user":{"displayName":"Andrey Petrunin","userId":"10287206466677589219"},"user_tz":-420},"id":"vWiaxe7oAyRa","outputId":"a62297ac-d551-468e-c658-670b26ac5d37"},"outputs":[{"output_type":"stream","name":"stdout","text":["File downloaded and saved as requirements.txt\n","File downloaded and saved as utils.py\n"]}],"source":["http_path = \"https://raw.githubusercontent.com/terrainternship/GPT_labsud/main/Petrunin/Streamlit/\"\n","dest_path = \"/content/\"\n","func_list = [\"requirements.txt\", \"utils.py\"]\n","for func_name in func_list:\n","  download_file_from_url(http_path+func_name, func_name)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":35350,"status":"ok","timestamp":1704551640537,"user":{"displayName":"Andrey Petrunin","userId":"10287206466677589219"},"user_tz":-420},"id":"ORj79NCgA3oK"},"outputs":[],"source":["!pip install -r requirements.txt\n","from IPython import display\n","display.clear_output()"]},{"cell_type":"markdown","source":["# Программа"],"metadata":{"id":"jaD9NhU9Nt1V"}},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":327,"status":"ok","timestamp":1704551726545,"user":{"displayName":"Andrey Petrunin","userId":"10287206466677589219"},"user_tz":-420},"id":"-jefpK0GYN1R","outputId":"bf8bfe53-b9f7-4280-834c-9736c04fce87"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing app.py\n"]}],"source":["%%writefile app.py\n","\n","import streamlit as st\n","import openai\n","import tiktoken\n","from openai import OpenAI\n","import os\n","\n","from utils import *\n","\n","def load_bd():\n","    if not st.session_state.is_federallab_bd:\n","        url_promt = \"https://raw.githubusercontent.com/terrainternship/GPT_labsud/main/Galina/FLSE_promt\"\n","        url_bd = 'https://github.com/terrainternship/GPT_labsud/raw/main/federallab_bd_index_v2.zip'\n","        url_question = 'https://github.com/terrainternship/GPT_labsud/raw/main/federallab_bd_question.zip'\n","        with st.spinner('Загрузка ...'):\n","            st.session_state.federallab_bd = load_bd_vect(url_bd)\n","            st.session_state.federallab_question = load_bd_question(\n","                url_question)\n","            st.session_state.federallab_promt = load_file(url_promt)\n","            st.session_state.is_federallab_bd = True\n","\n","dialog_depth = 3\n","\n","if \"openai_model\" not in st.session_state:\n","    st.session_state[\"openai_model\"] = \"gpt-3.5-turbo-1106\"\n","\n","if \"messages\" not in st.session_state:\n","    st.session_state.messages = [\n","        {\"role\": \"assistant\", \"content\": \"Наша фирма оказывает услуги по экспертизе и оценке. Чем могу я Вам помочь?\"}]\n","\n","if 'is_federallab_bd' not in st.session_state:\n","    st.session_state.is_federallab_bd = False\n","\n","with st.sidebar:\n","    openai_api_key = st.text_input(\n","        \"OpenAI API Key\", key=\"chatbot_api_key\", type=\"password\")\n","    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n","    if st.button(\"Загрузка Базы знаний...\", use_container_width=True):\n","        if not openai_api_key:\n","            st.info(\"Введите ваш OpenAI API key для продолжения.\")\n","            st.stop()\n","        load_bd()\n","    if st.session_state.is_federallab_bd:\n","        st.caption(\"База знаний загружена.\")\n","    else:\n","        st.caption(\"База знаний НЕ загружена.\")\n","    st.divider()\n","    if st.button(\"Новый диалог\", use_container_width=True):\n","        st.session_state.messages = [\n","            {\"role\": \"assistant\", \"content\": \"Наша фирма оказывает услуги по экспертизе и оценке. Чем могу я Вам помочь?\"}]\n","    st.divider()\n","\n","clientOpenAI = OpenAI(api_key=openai_api_key)\n","\n","with st.container():\n","    st.header(\"Нейро ассистент ФЛСЭ\")\n","    stick_it_good()\n","for message in st.session_state.messages:\n","    with st.chat_message(message[\"role\"]):\n","        st.markdown(message[\"content\"])\n","if query := st.chat_input(\"Введите свой вопрос.\"):\n","    if not openai_api_key:\n","        st.info(\"Введите ваш OpenAI API key для продолжения.\")\n","        st.stop()\n","    if not st.session_state.is_federallab_bd:\n","        load_bd()\n","    with st.chat_message(\"user\"):\n","        message_user = st.empty()\n","        message_user.markdown(query)\n","    with st.spinner('Думаю ...'):\n","        # Проверка вопроса на наличие в базе вопросов.\n","        is_query, bd_responce = find_query(\n","            st.session_state.federallab_question, query)\n","        if not is_query:\n","            # Формирование по диалогу уточняющего вопроса.\n","            if len(st.session_state.messages) > 1:\n","                refined_query = query_refiner(\n","                    client=clientOpenAI,\n","                    model=st.session_state[\"openai_model\"],\n","                    conversation=conversation_string(\n","                        st.session_state.messages, dialog_depth),\n","                    query=query)\n","            else:\n","                refined_query = query\n","            message_user.markdown(f\"{query} ({refined_query})\")\n","            st.session_state.messages.append(\n","                {\"role\": \"user\", \"content\": f\"{query} ({refined_query})\"})\n","            # Возвращение релевантных документов по запросу.\n","            content = bd_retrever(\n","                st.session_state.federallab_bd, refined_query)\n","            with st.chat_message(\"assistant\"):\n","                message_placeholder = st.empty()\n","                full_response = \"\"\n","                for response in clientOpenAI.chat.completions.create(\n","                    model=st.session_state[\"openai_model\"],\n","                    messages=[\n","                        {\"role\": \"system\", \"content\": st.session_state.federallab_promt},\n","                        {\"role\": \"user\",   \"content\": f\"Документ с информацией для ответа пользователю:\\n {content}.\\nВопрос клиента: {refined_query}\"}\n","                    ],\n","                    temperature=0,\n","                    stream=True,\n","                ):\n","                    full_response += (response.choices[0].delta.content or \"\")\n","                    message_placeholder.markdown(full_response + \"▌\")\n","                message_placeholder.markdown(full_response)\n","            st.session_state.messages.append(\n","                {\"role\": \"assistant\", \"content\": full_response})\n","        else:\n","            message_user.markdown(f\"{query} (ответ из базы вопросов)\")\n","            st.chat_message(\"assistant\").markdown(bd_responce)\n","\n","            st.session_state.messages.append(\n","                {\"role\": \"user\", \"content\": f\"{query} (ответ из базы вопросов)\"})\n","            st.session_state.messages.append(\n","                {\"role\": \"assistant\", \"content\": bd_responce})\n"]},{"cell_type":"markdown","metadata":{"id":"wiL-OHx4Av5N"},"source":["# Запуск WEB-приложения через тунель."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"UckLkSWLbVFP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704551912020,"user_tz":-420,"elapsed":156377,"user":{"displayName":"Andrey Petrunin","userId":"10287206466677589219"}},"outputId":"7f36eb1b-262e-4f6c-cbd9-2e6f8c2664a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["[##................] - fetchMetadata: sill resolveWithNewModule yargs-parser@20\u001b[0m\u001b[K\n","Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n","\u001b[0m\n","\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n","\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://104.196.158.131:8501\u001b[0m\n","\u001b[0m\n","\u001b[K\u001b[?25hnpx: installed 22 in 2.853s\n","your url is: https://soft-cases-add.loca.lt\n","/usr/local/lib/python3.10/dist-packages/langchain/vectorstores/__init__.py:35: LangChainDeprecationWarning: Importing vector stores from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n","\n","`from langchain_community.vectorstores import FAISS`.\n","\n","To install langchain-community run `pip install -U langchain-community`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.OpenAIEmbeddings instead.\n","  warn_deprecated(\n","\u001b[34m  Stopping...\u001b[0m\n","^C\n"]}],"source":["!streamlit run app.py & npx localtunnel --port 8501"]},{"cell_type":"markdown","metadata":{"id":"wJ2U77XjBBqG"},"source":["1. Запускаем ячейку с кодом - !streamlit run app.py & npx localtunnel --port 8501"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":504},"executionInfo":{"elapsed":334,"status":"ok","timestamp":1704550242989,"user":{"displayName":"Andrey Petrunin","userId":"10287206466677589219"},"user_tz":-420},"id":"PIs7e-nLHIPf","outputId":"aa08311b-1a0e-4514-c77a-4f2bdb67cf2c"},"outputs":[{"data":{"text/html":["<iframe src=\"https://drive.google.com/file/d/1KbsjKtHAiC3URPoOEIrjshCZjL6IgrT0/preview\" width=\"640\" height=\"480\" allow=\"autoplay\"></iframe>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["#Порядок запуска. Запустите ячейку откроется картинка.\n","\n","%%html\n","<iframe src=\"https://drive.google.com/file/d/1KbsjKtHAiC3URPoOEIrjshCZjL6IgrT0/preview\" width=\"640\" height=\"480\" allow=\"autoplay\"></iframe>"]}],"metadata":{"colab":{"provenance":[{"file_id":"1CyLdLXIbach9meNlVzqp1UcEU5xlYkxk","timestamp":1703657979918}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}