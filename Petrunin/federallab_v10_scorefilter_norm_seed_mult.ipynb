{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1GUqW7Uc_UbP_cxB6d33RCKNU1FDwAhzx","timestamp":1701765899532},{"file_id":"1y1clTRCmzcpACPTC11R_2woHGLH_HROp","timestamp":1701597533465},{"file_id":"1uW37hOuhfFOtaLAvfyEOWFJXoCqY9F2R","timestamp":1701580759507},{"file_id":"1ejLUPjvI7CDcXw_mYaci543FXAkmp5KD","timestamp":1701418054054},{"file_id":"1Za6DfnqQ93SGS-2nSmEXKL-gifYwTty5","timestamp":1701183257824},{"file_id":"11e2TyoAf05rSk9vM0nW8oyt0oMFKP2Hp","timestamp":1701148066991},{"file_id":"14hIz4MZfkMg6y4IzG2KIAlICGzMh8g35","timestamp":1700802837507},{"file_id":"1bXhyU9R_nE9ZiSDMdpojNa-ktVBnqe7P","timestamp":1700373712614}],"authorship_tag":"ABX9TyM33AjHOcbmuoR/grNsZ+CX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#@title Импорт библиотек.\n","\n","# Фиксируем версии библиотек на 22.11.2023\n","!pip  install  tiktoken==0.5.1\n","!pip  install  langchain==0.0.339\n","!pip  install  openai==1.3.4\n","!pip  install  faiss-cpu==1.7.4\n","!pip install gspread==3.4.2\n","\n","from langchain.vectorstores import FAISS\n","from langchain.docstore.document import Document\n","from langchain.embeddings.openai import OpenAIEmbeddings\n","from langchain.text_splitter import MarkdownHeaderTextSplitter\n","\n","import requests\n","import os\n","import re\n","import getpass\n","import openai\n","import tiktoken\n","from openai import OpenAI\n","import zipfile\n","from IPython import display\n","import timeit\n","import time\n","from collections import Counter\n","from textwrap import fill\n","\n","import gspread                  # Импортируем API для работы с Google таблицами\n","from google.colab import auth   # Импортируем модуль для аутентификации\n","from google.auth import default # Импортируем модуль для работы с учетными данными\n","\n","# Очистить экран.\n","display.clear_output()"],"metadata":{"id":"iO9CMx_FvOOq","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Ввод ключа к API OpenAI.\n","\n","openai.api_key = getpass.getpass(\"Введите OpenAi API key:\")\n","os.environ[\"OPENAI_API_KEY\"] = openai.api_key"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F9jZlKHIWRsk","executionInfo":{"status":"ok","timestamp":1703655482351,"user_tz":-420,"elapsed":12465,"user":{"displayName":"Andrey Petrunin","userId":"10287206466677589219"}},"outputId":"2d5478d9-40b5-4273-de8b-cc8e5b6ea274","cellView":"form"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Введите OpenAi API key:··········\n"]}]},{"cell_type":"code","source":["#@title Вспомогательные функции\n","\n","def num_tokens_from_string(string: str) -> int:\n","    \"\"\"Возвращает количество токенов в строке\"\"\"\n","    # Выбор кодировщика. `cl100k_base`используется для `gpt-4`, `gpt-3.5-turbo`, `text-embedding-ada-002`\n","    encoding = tiktoken.get_encoding(\"cl100k_base\")\n","    # Разбивка строки на токены и подсчет из количества.\n","    num_tokens = len(encoding.encode(string))\n","    return num_tokens\n","\n","def split_text(text, verbose=0):\n","    \"\"\" Функция разбивает текст на чанки. \"\"\"\n","    # Шаблон MarkdownHeaderTextSplitter по которому будет делится переданный\n","    # текст в формате Markdown.\n","    headers_to_split_on = [ (\"#\",    \"Header 1\"),\n","                            (\"##\",   \"Header 2\"),\n","                            (\"###\",  \"Header 3\"),\n","                            (\"####\", \"Header 4\")\n","                        ]\n","    # Создаем экземпляр спилиттера.\n","    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n","    # Получаем список чанков.\n","    source_chunks = markdown_splitter.split_text(text)\n","\n","    # Обработка чанков.\n","    chank_count = len(source_chunks)\n","    for number, chank in enumerate(source_chunks):\n","        # Добавление информации в метаданные чанка о его номере в базе.\n","        chank.metadata[\"chank\"]=f'{number+1}/{chank_count}'\n","        # Вывод количества слов/токенов в фрагменте, если включен режим verbose.\n","        if verbose:\n","            count = num_tokens_from_string(chank.page_content)\n","            print(f\"\\n Chank#{number+1}/{chank_count}. Tokens in text = {count}\\n {'-' * 20}\\n{insert_newlines(str(chank))}\\n{'=' * 20}\")\n","\n","    # Возвращение списка фрагментов текста.\n","    return source_chunks\n","\n","def create_embedding(data, verbose=0):\n","    \"\"\"Функция преобразует текстовую Базу знаний в векторную.\"\"\"\n","    # Разбивка текста на чанки.\n","    source_chunks = []\n","    source_chunks = split_text(text=data, verbose=verbose)\n","\n","    # Создание векторной Базы знаний на основе чанков.\n","    search_index = FAISS.from_documents(source_chunks, OpenAIEmbeddings(), )\n","    # Подсчет общего количества токенов во всех чанках.\n","    count_token = num_tokens_from_string(' '.join([x.page_content for x in source_chunks]))\n","    # Печать сводной информации по созданию векторной Базы знаний.\n","    print('\\n==================== ')\n","    print('Количество токенов в документе :', count_token)\n","    # Стоимость эмбэндинга согласно прайса на 22.11.2023 - 0,0001/1К токенов.\n","    # https://openai.com/pricing#language-models\n","    print('ЦЕНА запроса:', 0.0001*(count_token/1000), ' $')\n","    print('==================== ')\n","    return search_index\n","\n","def load_file(url: str):\n","    \"\"\" Функция загрузки документа по url как текст.\"\"\"\n","    try:\n","        response = requests.get(url) # Получение документа по url.\n","        response.raise_for_status()  # Проверка ответа и если была ошибка - формирование исключения.\n","        return response.text\n","    except Exception as e:\n","        print(e)\n","\n","def load_search_indexes(url: str, verbose=0):\n","    \"\"\"Функция загружает текстовую Базу знаний и преобразует ее в векторную.\"\"\"\n","    try:\n","        return create_embedding(load_file(url), verbose=verbose)\n","    except Exception as e:\n","        print(e)\n","\n","def insert_newlines(text: str, max_len: int = 120) -> str:\n","    \"\"\" Функция форматирует переданный текст по длине\n","    для лучшего восприятия на экране.\"\"\"\n","    words = text.split()\n","    lines = []\n","    current_line = \"\"\n","    for word in words:\n","        if len(current_line + \" \" + word) > max_len:\n","            lines.append(current_line)\n","            current_line = \"\"\n","        current_line += \" \" + word\n","    lines.append(current_line)\n","    return \"\\n\".join(lines)\n","\n","def filtred_docs (docs, limit_score):\n","    \"\"\" Функция удаляет из отобранных чанков чанки у которых score выше значения limit_score.\n","    При этом limit_score определяет гарантированно ошибочные чанки.\n","    Далее отбор чанков идет в зависимости от значения score первого не нулевого\n","    score. Если есть чанк с score=0 он оставляется единственным.\n","    Если limit_score = 0, то чанки не фильтруются.\"\"\"\n","    if bool(limit_score):\n","        r = []\n","        score = 0\n","        def set_score(d, sc):\n","            d[0].metadata[\"score\"]=sc\n","            return d\n","        for doc in docs:\n","            s = doc[1]\n","            if s==0:\n","                r.append( set_score(doc[0],s))\n","                break\n","            if score==0:\n","                if s<.2:\n","                    score = s*1.7\n","                elif s<.3:\n","                    score = s +.05\n","                else:\n","                    score = s +.01\n","                if score>limit_score:\n","                        score = limit_score\n","            if s<score:\n","                    r.append(set_score(doc,s))\n","        print(f'Фильр пропустил чанк(ов): {len(r)} из {len(docs)}')\n","    else:\n","        r = docs\n","    return r\n","\n","def search_answers_maximum_repetition(list_answer):\n","    \"\"\" \"\"\"\n","    len_counter = Counter(len(i[\"answer\"]) for i in list_answer if \"answer\" in i)\n","    length_max = max(len_counter.values())\n","    key_max = [k for k, v in len_counter.items() if v == length_max][0]\n","    found_answer = [dict[\"answer\"] for dict in list_answer if len(dict[\"answer\"]) == key_max][0]\n","    return found_answer, length_max\n","\n","def answer_index(model, system, topic: str, query, search_index, temp = 0, seed = 1235, verbose_documents = 0,  verbose_price = 0, top_documents = 3, limit_score = 0.0):\n","    \"\"\" Основная функция которая формирует запрос и получает ответ от OpenAI по заданному вопросу\n","    на основе векторной Базы знаний. \"\"\"\n","\n","    # Выбор варианта вопроса. Если есть query, то вопрос задан из группового запроса и он имеет приоритет.\n","    question = query[\"question\"] if bool(query) else topic\n","    seed = query[\"seed\"] if bool(query) and not query.get('seed')==None else seed\n","    # Выборка релевантных чанков.\n","    docs = filtred_docs(search_index.similarity_search_with_score(question, k=top_documents), limit_score)\n","\n","    \"\"\" Этот блок закоментирован. Рассматривается возможность даполнительного\n","    запроса с фильтрацией чанков по метаданным. Пока нереализовано.\"\"\"\n","    # for i, doc in enumerate(docs):\n","    #     header1 = doc[0].metadata.get('Header 1')\n","    #     print(f'{i}. {header1}. Score: {doc[1]}')\n","    #     if header1=='Оценка' or header1=='Экспертиза':\n","    #         #docs = search_index.similarity_search_with_score(question, k=top_documents, )\n","    #         #print(f'{i}. {header1}. Score: {doc[1]}')\n","    #         pass\n","\n","\n","    message_content = \"\"            # Контекст для GPT.\n","    message_content_display = \"\"    # Контекст для вывода на экран.\n","    for i, doc in enumerate(docs):\n","        # Формирование контекста для запроса GPT и показа на экран отобранных чанков.\n","        message_content = message_content + f'Отрывок документа №{i+1}:{doc[0].page_content}'\n","        message_content_display = message_content_display + f\"\\n Отрывок документа №{i+1}. Chank № {doc[0].metadata.get('chank')}. Score({str(round(doc[1], 3))})\\n -----------------------\\n{insert_newlines(doc[0].page_content)}\\n\"\n","\n","        # Сбор информации для группого запроса.\n","        if bool(query):\n","            # Выделение из строки метаданных ссылки. Если нет - присваиваем пустую строку.\n","            search_link_h1 = re.search(r'\\[(.*?)\\]', doc[0].metadata.get('Header 1')) if bool(doc[0].metadata.get('Header 1')) else \"\"\n","            search_link_h2 = re.search(r'\\[(.*?)\\]', doc[0].metadata.get('Header 2')) if bool(doc[0].metadata.get('Header 2')) else \"\"\n","            search_link_h3 = re.search(r'\\[(.*?)\\]', doc[0].metadata.get('Header 3')) if bool(doc[0].metadata.get('Header 3')) else \"\"\n","            search_link_h4 = re.search(r'\\[(.*?)\\]', doc[0].metadata.get('Header 4')) if bool(doc[0].metadata.get('Header 4')) else \"\"\n","            # Выбор самой внутренней ссылки. Если несколько ссылок, то самая внутренняя ссылается на расположение чанка на сайте.\n","            link = ''\n","            if bool(search_link_h4):\n","                link = search_link_h4.group(1)\n","            elif bool(search_link_h3):\n","                link = search_link_h3.group(1)\n","            elif bool(search_link_h2):\n","                link = search_link_h2.group(1)\n","            elif bool(search_link_h1):\n","                link = search_link_h1.group(1)\n","            # Заполнение запроса выбранными чанками.\n","            query[f\"chank_{i+1}\"] = f\"Chank № {doc[0].metadata.get('chank')}. Score({str(round(doc[1], 3))}).\\n{doc[0].page_content}.\\n--------\\n{link}\"\n","\n","    # Вывод на экран отобранных чанков.\n","    if (verbose_documents):\n","        print(message_content_display)\n","\n","    # Отправка запроса к Open AI.\n","    completion = OpenAI().chat.completions.create(\n","        model = model[0],\n","        messages = [\n","            {\"role\": \"system\", \"content\": system } ,\n","            {\"role\": \"user\", \"content\": f\"Документ с информацией для ответа пользователю : {message_content}.\\n\\nВопрос клиента: {question}\"}\n","        ],\n","        temperature=temp,\n","        seed = seed,\n","    )\n","\n","    # Подсчет токенов и стоимости.\n","    system_fingerprint = completion.system_fingerprint\n","    prompt_tokens = completion.usage.prompt_tokens\n","    total_tokens = completion.usage.total_tokens\n","    price_promt_tokens = prompt_tokens * model[1]/1000\n","    price_answer_tokens = (total_tokens - prompt_tokens) * model[2]/1000\n","    price_total_token = price_promt_tokens + price_answer_tokens\n","    # Сбор информации для группого запроса.\n","    if bool(query):\n","        query[\"price_query\"] = price_total_token\n","        query[\"price_question\"] = price_promt_tokens\n","        query[\"price_answer\"] = price_answer_tokens\n","        query[\"token_query\"] = total_tokens\n","        query[\"token_question\"] = prompt_tokens\n","        query[\"token_answer\"] = total_tokens - prompt_tokens\n","        query[\"system_fingerprint\"] = system_fingerprint\n","        query[\"seed\"] = seed\n","    # Вывод на экран стоимости запроса.\n","    if (verbose_price):\n","        print('\\n======================================================= ')\n","        print(f'{prompt_tokens} токенов использовано на вопрос. Цена: {round(price_promt_tokens, 6)} $.')\n","        print(f'{total_tokens - prompt_tokens} токенов использовано на ответ.  Цена: {round(price_answer_tokens, 6)} $.')\n","        print(f'{total_tokens} токенов использовано всего.     Цена: {round(price_total_token, 6)} $')\n","        print('======================================================= ')\n","        print(f\"seed = {seed}, system_fingerprint = {system_fingerprint}, len = {len(completion.choices[0].message.content)}\")\n","        print('======================================================= ')\n","\n","    # Ответ OpenAI.\n","    return completion.choices[0].message.content\n","\n","#question_normalization\n","def question_normalization(text):\n","    \"\"\" Функция нормализует текст вопроса. Удаляет лишние пробелы,\n","    символы, знаки. Делает первое слово с заглавной буквы.\"\"\"\n","\n","    # Удаление символов \"!?.,-\" из текста\n","    #text = re.sub(r'[-!?_]', '', text) # '[-!?.,_]'\n","    # Разделение текста на слова\n","    words = text.split()\n","    # # Проход по каждому слову\n","    # for i in range(len(words)):\n","    #     # Если слово состоит из заглавных букв и длина больше 1 символа, считаем это аббревиатурой\n","    #     if words[i].isupper() and len(words[i]) > 1:\n","    #         continue  # Пропускаем аббревиатуры\n","    #     else:\n","    #         words[i] = words[i].lower()  # Преобразуем в нижний регистр\n","    # # Преобразуем первое слово в строке к верхнему регистру\n","    #words[0] = words[0].capitalize()\n","    # Объединяем слова обратно в строку\n","    return ' '.join(words)\n","\n","def load_bd_text(url: str, verbose=0):\n","    \"\"\" Функция загружает текстовую Базу знаний и\n","        преобразует ее в векторную.\"\"\"\n","    response = requests.get(url) # Получение документа по url.\n","    response.raise_for_status()  # Проверка ответа и если была ошибка - формирование исключения.\n","    return create_embedding(response.text, verbose=verbose)\n","\n","def load_bd_vect(url: str, verbose=0):\n","    \"\"\" Функция загружает векторную Базу знаний.\"\"\"\n","    name_bd = 'federallab_bd_index.zip'\n","    # Скачивание архива Базы знаний\n","    response = requests.get(url) # Получение документа по url.\n","    response.raise_for_status()  # Проверка ответа и если была ошибка - формирование исключения.\n","    # Сохранение архива.\n","    with open(name_bd, 'wb') as file:\n","        file.write(response.content)\n","    # Разархивирование Базы знаний.\n","    with zipfile.ZipFile(name_bd, 'r') as zip:\n","        zip.extractall()\n","    # Загрузка векторной Базы знаний.\n","    federallab_bd = FAISS.load_local(f'federallab_bd_index', OpenAIEmbeddings())\n","\n","    if verbose :\n","        docs = federallab_bd.similarity_search_with_score('', k=10000)\n","        docs_sorted = sorted(docs, key=lambda x: int(x[0].metadata.get('chank').split('/')[0]))\n","        for doc in docs_sorted:\n","            count = num_tokens_from_string(doc[0].page_content)\n","            print(f\"\\n Chank#{doc[0].metadata.get('chank')}. Tokens in text = {count}\\n {'-' * 20} \\n{insert_newlines(str(doc))}\\n{'=' * 20}\")\n","        print()\n","    return federallab_bd\n","\n","def load_bd (url_vect: str, url_text: str, verbose=0):\n","    \"\"\" Функция организует очередность загрузки Базы знаний.\n","        Сначала идет загрузка векторной базы, если она не загружается,\n","        то загружается база в текстовом формате и потом преобразуется в векторную.\"\"\"\n","    try:\n","        federallab_bd = load_bd_vect(url_vect, verbose)\n","        print(\"Загрузка векторной Базы знаний выполнена успешно.\")\n","        return federallab_bd\n","    except Exception as e:\n","        print(\"По указанной ссылке векторной Базы знаний нет.\")\n","        print(e)\n","        print(\"\\nИдет загрузка текстовой Базы знаний...\")\n","        try:\n","            federallab_bd = load_bd_text(url_text, verbose)\n","            print(\"\\nЗагрузка текстовой Базы знаний выполнена успешно.\")\n","            return federallab_bd\n","        except Exception as e:\n","            print(\"\\nПо указанной ссылке текстовой Базы знаний нет.\")\n","            print(e)\n","            print(\"\\nОшибка загрузки!!\")"],"metadata":{"id":"wr9jQm4dvOeR","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Выбор источника Базы знаний. { run: \"auto\", vertical-output: true }\n","\"\"\" !!! ПАРМЕТРЫ БАЗЫ ЗНАНИЙ !!! \"\"\"\n","\n","\"\"\" Сначала идет попытка загрузки векторной БЗ, если она неудачна, то идет загрузка текстовой БЗ.\n","\n","================== ЧИТАЙТЕ СООБЩЕНИЯ ЧТО ЗАГРУЗИЛОСЬ!! ==================================== \"\"\"\n","\n","# Сылка на Базу знаний на Github в текстовом формате.\n","link_bd_text = \"https://raw.githubusercontent.com/terrainternship/GPT_labsud/main/Datadase/LabSudDB_v1.md\" #@param string\n","# Сылка на Базу знаний на Github в векторном формате.\n","link_bd_vect = '-https://github.com/terrainternship/GPT_labsud/raw/main/federallab_bd_index_v2.zip' #@param string\n","\n","# Показывать полученные чанки.\n","verbose_bd = 0 #@param Показывать полученные чанки string\n","\n","# Загрузка Базы знаний.\n","federallab_bd_index = load_bd(link_bd_vect, link_bd_text, verbose=verbose_bd )"],"metadata":{"id":"jFOoW7AKvOjH","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Архивирование Базы знаний (при необходимости).\n","\n","# В дальнейшем архив нужно поместить на GitHub\n","archive = False\n","if archive:\n","    folder_to_zip = 'federallab_bd_index'\n","    output_filename = 'federallab_bd_index_v2.zip'\n","    # Сохранение папки с векторной Базой знаний.\n","    federallab_bd_index.save_local(folder_to_zip)\n","    # Архивирование папки с векторной Базой знаний\n","    with zipfile.ZipFile(output_filename, 'w') as zip:\n","        for root, dirs, files in os.walk(folder_to_zip):\n","            for file in files:\n","                zip.write(os.path.join(root, file))\n","    print(f'База знаний - заархивирована. Имя файла - {output_filename}.')\n","else:\n","    print(f'База знаний - НЕ заархивирована. Установите archive = True.')"],"metadata":{"id":"yuUMoySioISO","executionInfo":{"status":"ok","timestamp":1701667016605,"user_tz":-420,"elapsed":276,"user":{"displayName":"Andrey Petrunin","userId":"10287206466677589219"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"de5b6b1d-e00e-4fee-b5cc-1010a81c7789","cellView":"form"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["База знаний - НЕ заархивирована. Установите archive = True.\n"]}]},{"cell_type":"code","source":["# @title Параметры нейро-консультатнта { run: \"auto\", vertical-output: true }\n","\n","\"\"\" !!! ПАРАМЕТРЫ НЕЙРО-КОНСУНТАЛЬТА !!! \"\"\"\n","\n","# Данные по названиям модели и стоимости токена на 22.11.2023.\n","# https://openai.com/pricing#language-models\n","# Псевдоним = ['Имя модели', 'Цена токена - вопроса', 'Цена токена - ответа'].\n","MODEL_GPT_4_1106_PREVIEW = ['gpt-4-1106-preview', 0.01, 0.03]   # 128K tokens\n","MODEL_GPT_3_5_TURBO_1106 = ['gpt-3.5-turbo-1106', 0.001, 0.002] #  16K tokens\n","\n","SELECT_MODEL_GPT = MODEL_GPT_3_5_TURBO_1106\n","MODEL_GPT = \"gpt-3.5-turbo-1106\" # @param [\"gpt-3.5-turbo-1106\", \"gpt-4-1106-preview\"]\n","if MODEL_GPT == \"gpt-3.5-turbo-1106\": SELECT_MODEL_GPT = MODEL_GPT_3_5_TURBO_1106\n","if MODEL_GPT == \"gpt-4-1106-preview\": SELECT_MODEL_GPT = MODEL_GPT_4_1106_PREVIEW\n","\n","top_documents = 3      #@param {type:\"integer\"}     # Количество отобранных чанков.\n","temperature = 0        #@param  float               # Вариативность ответа.\n","seed = 1235             #@param  {type:\"integer\"}    # Фиксация повторяемости ответа.\n","limit_score = 0        #@param  float               # Отфильтровывать чанки при поиске выше этого значения, если \"0\" - не фильтровать\n","question_norma = True # @param {type:\"boolean\"}    # Нормализовать вопрос. - Удаляет лишние пробелы из вопроса.\n","url_promt = \"https://raw.githubusercontent.com/terrainternship/GPT_labsud/main/Galina/FLSE_promt\" # @param {type:\"string\"}\n","# Запускают режим выбора ответа из множества ответов. Выбирается ответ наиболее часто повторяющийся.\n","repeat_question = True # @param {type:\"boolean\"}\n","repeat_count = 5 # @param integer\n","# Загрузка промта.\n","federallab_chat_promt = load_file(url_promt)"],"metadata":{"id":"JHJLOxt0lpbj","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Одиночный запрос. (параметр repeat_question/количество повторных запросов - только для одиночного запроса) { vertical-output: true }\n","\n","# Настройки только для одиночного запроса.\n","verbose_chank = 0 # @param {type:\"integer\"}  # Показывать отобранные чанки.\n","verbose_price = 0 # @param {type:\"integer\"}      # Показывать стоимость запроса.\n","\n","question = \"\\u042D\\u043A\\u0441\\u043F\\u0435\\u0440\\u0442\\u0438\\u0437\\u0430 \\u043F\\u043E\\u0434\\u043B\\u0438\\u043D\\u043D\\u043E\\u0441\\u0442\\u0438\" # @param {type:\"string\"}\n","\n","# Нормализация вопроса при необходимости.\n","question = question_normalization(question) if question_norma else question\n","count_question = repeat_count if repeat_question else 1\n","# Список ответов\n","list_answer = []\n","# Запрос GPT\n","for i in range(count_question):\n","    answer = answer_index(\n","        model = SELECT_MODEL_GPT,\n","        system = federallab_chat_promt,\n","        topic = question,\n","        query = '',\n","        search_index = federallab_bd_index,\n","        temp = temperature,\n","        seed = seed,\n","        verbose_documents = verbose_chank,\n","        verbose_price = verbose_price,\n","        top_documents = top_documents,\n","        limit_score = limit_score,\n","    )\n","    dict_answer = {\n","        'length': len(answer),\n","        'answer': answer,\n","    }\n","    list_answer.append(dict_answer)\n","# Выбор ответа из списка из условия максимального количества повторов.\n","answer, length_max = search_answers_maximum_repetition(list_answer)\n","# Дополнительная информация при множнственных ответах.\n","message_answer = f\" (Ответ выбран из {len(list_answer)} ответов. Количество повторов: {length_max}/{len(list_answer)} Длина ответа - {len(answer)} символов.)\" if repeat_question else \"\"\n","\n","print()\n","print(f' ВОПРОС:\\n{insert_newlines(question)}\\n')\n","print(f' ОТВЕТ{message_answer}:\\n{insert_newlines(answer)}')"],"metadata":{"id":"anmfl4qteI7Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703657056675,"user_tz":-420,"elapsed":51578,"user":{"displayName":"Andrey Petrunin","userId":"10287206466677589219"}},"outputId":"1ab923e9-b78b-45fd-d7ad-e7e8147c6737","cellView":"form"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," ВОПРОС:\n"," Экспертиза подлинности\n","\n"," ОТВЕТ (Ответ выбран из 5 ответов. Количество повторов: 2/5 Длина ответа - 472 символов.):\n"," Экспертиза подлинности документов проводится в рамках судебной экспертизы документов. Наша компания предоставляет\n"," услуги по установлению признаков технической подделки документа, установлению способа изготовления документа, а также\n"," определению очередности нанесения реквизитов документа. Мы также можем провести экспертизу проверки документов на\n"," подлинность в уголовных и гражданских делах. Если вам нужна дополнительная информация или услуги, пожалуйста, дайте мне\n"," знать.\n"]}]},{"cell_type":"code","source":["# @title Групповой запрос. Подключение к таблице. { run: \"auto\", vertical-output: true }\n","\n","\"\"\" <<<< ЖМЕМ \"\"\"\n","\n","auth.authenticate_user()        # Аутентифицируем текущего пользователя Colab\n","creds, _ = default()            # Создаем объект учетных данных на основе аутентификации\n","gc = gspread.authorize(creds)   # Создаем клиент для таблиц на основе учетных данных\n","\n","# Глобальная переменная список листов.\n","worksheet_list = []\n","\n","# Название файла с вопросами.\n","# Ссылка на общий файл.\n","try:\n","    url_table = 'https://docs.google.com/spreadsheets/d/1p69Ma_vcEU86_lde61l5RtawJIbGwpAhpXHo2DEKNDo/edit#gid=1834702311'#@param string\n","    spreadsheet = gc.open_by_url('https://docs.google.com/spreadsheets/d/1p69Ma_vcEU86_lde61l5RtawJIbGwpAhpXHo2DEKNDo/edit#gid=1834702311')\n","    print(f'Подключились к документу - {spreadsheet.title}')\n","    # Получаем список всех страниц файла.\n","    worksheet_list = spreadsheet.worksheets()\n","    print('\\nСтраницы документа:')\n","    print('-------------------')\n","    for i, worksheet in enumerate(worksheet_list):\n","            print(f'{i}. {worksheet.title}')\n","\n","except Exception as e:\n","    print(e)\n","    print(f'Ошибка подключения к документу. Проверьте ссылку.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sc7NKHpJ1_DV","executionInfo":{"status":"ok","timestamp":1703655622997,"user_tz":-420,"elapsed":23400,"user":{"displayName":"Andrey Petrunin","userId":"10287206466677589219"}},"outputId":"0d9e63fc-393e-44ac-9244-e6dbb048f713","cellView":"form"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Подключились к документу - FederalLab\n","\n","Страницы документа:\n","-------------------\n","0. Инструкции\n","1. Страницы\n","2. Галина\n","3. Докумов\n","4. Макеев\n","5. Петрунин\n","6. Шляпников\n","7. Бугаев\n","8. A.Куцинс\n","9. Вопросы FineTune\n","10. Исключенные\n"]}]},{"cell_type":"code","source":["# @title Выбор страницы в таблице. { run: \"auto\", vertical-output: true }\n","\n","\"\"\" <<<< ЖМЕМ \"\"\"\n","# Устанавливаем номер рабочего листа по списку выше.\n","name_person = \"Петрунин\" # @param {type:\"string\"}\n","\n","number_sheet = None\n","for i, worksheet in enumerate(worksheet_list):\n","    if worksheet.title == name_person:\n","            number_sheet = i\n","if number_sheet == None:\n","    print(f\"Указано не верное имя ответственного. Смотрите список выше. \")\n","\n","#number_sheet = 5 # @param {type:\"integer\"} # Петрунин=6\n","\n","if not number_sheet==None:\n","    # Выбор нужного листа из списка.\n","    worksheet = worksheet_list[number_sheet]\n","    # Проверка текущей страницы.\n","    print(f'Текущая страница - \"{worksheet.title}\"\\n')\n","    # Список всех столбцов на странице.\n","    print('-----№---------Название---')\n","    for i, col in enumerate(worksheet.row_values(1)):\n","        print(f'Колонка № {i}. {col}')\n","else:\n","    print('Введите номер страницы.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FU2wYL41q1Zd","executionInfo":{"status":"ok","timestamp":1703655645057,"user_tz":-420,"elapsed":646,"user":{"displayName":"Andrey Petrunin","userId":"10287206466677589219"}},"outputId":"36e725bf-7364-497e-ed8d-f1331ed5af77","cellView":"form"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Текущая страница - \"Петрунин\"\n","\n","-----№---------Название---\n","Колонка № 0. Ответственный\n","Колонка № 1. URL\n","Колонка № 2. Название\n","Колонка № 3. Вопрос\n","Колонка № 4. Ожидаемый ответ\n","Колонка № 5. Ответ GPT\n","Колонка № 6. Оценка\n","Колонка № 7. Ошибка\n","Колонка № 8. Ком-рий\n","Колонка № 9. Чанк №1\n","Колонка № 10. Чанк №2\n","Колонка № 11. Чанк №3\n","Колонка № 12. seed\n","Колонка № 13. system_fingerprint\n"]}]},{"cell_type":"code","source":["# @title Загрузка вопросов. { run: \"auto\", vertical-output: true }\n","\n","column_question = 3 # @param {type:\"integer\"} #\n","verbose_question = 0 # @param {type:\"integer\"} #\n","\n","# В данном блоке происходит заполнение списка запросов вопросами и дополнительной\n","# информацией с выбранного листа. Загрузка выполняется ВСЕХ строк с вопросами для\n","# последующей корректной работы. Далее из этого списка выбирается нужный диапазон\n","# вопросов для группового запроса к GPT.\n","\n","# Выбор всех вопросов.\n","column = worksheet.col_values(column_question)\n","if question_norma: print(\"Вопросы будут нормализованы.\")\n","# Создаем пустой список запросов.\n","list_query = []\n","# Заполнение списка запросов информацией с выбранного листа.\n","for i in range(len(column)-1):\n","    row = worksheet.row_values(i+2)\n","    # Считывание ячеек с контролем их наличия для избежании ошибки чтения.\n","    # Проверить индексы row со списком в ячейке выше.\n","    person = row[0] if len(row)>=1 else \"\"      # Автор вопроса.\n","    link = row[1] if len(row)>=2 else \"\"        # Ссылка на тему.\n","    subject = row[2] if len(row)>=3 else \"\"     # Тема вопроса.\n","    question = row[3] if len(row)>=4 else \"\"    # Вопрос.\n","    answer = row[4] if len(row)>=5 else \"\"      # Ожидаемый ответ.\n","    answer_gpt = row[5] if len(row)>=6 else \"\"  # Ответ GPT.\n","    appraisal = row[6] if len(row)>=7 else \"\"   # Оценка.\n","    seed_group = int(row[12]) if len(row)>=13 and not row[12] == None else seed    # Фиксатор повторяемости.\n","    system_fingerprint = row[13] if len(row)>=14 else \"\"   # Отпечаток ответа системы.\n","    # Нормализация вопроса.\n","    question = question_normalization(question) if question_norma else question\n","    # Словарь запроса.\n","    query = {\n","        \"line\": i+2,                # Номер строки в документе. Берем строки с вопросами.\n","        \"person\": person,           # Автор вопроса.\n","        \"subject\": subject,         # Тема вопроса.\n","        \"link\": link,               # Ссылка на тему.\n","        \"question\": question,       # Вопрос.\n","        \"answer\": answer,           # Ожидаемый ответ.\n","        \"answer_gpt\": answer_gpt,   # Ответ GPT.\n","        \"appraisal\": appraisal,     # Оценка ответа.\n","        \"bug\": \"\",                  # Ошибка.\n","        \"comments\": \"\",             # Комментарии.\n","        \"chank_1\": \"\",              # Чанк №1.\n","        \"chank_2\": \"\",              # Чанк №2.\n","        \"chank_3\": \"\",              # Чанк №3.\n","        \"price_query\": 0,           # Стоимость запроса общая.\n","        \"price_question\": 0,        # Стоимость вопроса с контекстом.\n","        \"price_answer\": 0,          # Стоимость ответа.\n","        \"token_query\": 0,           # Количество токенов всего вопро-ответ.\n","        \"token_question\": 0,        # Количество токенов в вопросе с контекстом.\n","        \"token_answer\": 0,          # Количество токенов в ответе.\n","        \"seed\": seed_group,         # Фиксатор повторяемости.\n","        \"system_fingerprint\": system_fingerprint  # Отпечаток ответа системы.\n","\n","    }\n","    list_query.append(query)\n","# Вывод вопросов.\n","if verbose_question:\n","    for query in list_query:\n","        print(f'Строка №{query[\"line\"]}. Вопрос: {query[\"question\"]}')\n","\n","# Диапазон строк с вопросами на выбранной странице.\n","print(f'\\n\\nЗагрузка списка вопросов завершена. Количество вопросов: {len(column)-1}.')\n","print(f\"Диапазон номеров строк с вопросами (включительно): [{list_query[0]['line']}:{list_query[-1]['line']}].\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bu3B8D_4OW89","executionInfo":{"status":"ok","timestamp":1703657102379,"user_tz":-420,"elapsed":10807,"user":{"displayName":"Andrey Petrunin","userId":"10287206466677589219"}},"outputId":"a4886acc-e62f-46e0-d122-4a2c6d523238","cellView":"form"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Вопросы будут нормализованы.\n","\n","\n","Загрузка списка вопросов завершена. Количество вопросов: 60.\n","Диапазон номеров строк с вопросами (включительно): [2:61].\n"]}]},{"cell_type":"code","source":["# @title Выбор диапазона вопросов группого запроса. Отправка запроса. (для примера работа только с одним вопросом на 2 строке: row_first=2, row_end=2) { vertical-output: true }\n","\n","# Определение диапазона строк с вопросами. Начало диапазона, конец диапазона (включительно).\n","row_first = 2 # @param {type:\"integer\"}\n","row_end = 2 # @param {type:\"integer\"}\n","verbose_answer = 0 #@param {type:\"integer\"}\n","verbose_chank = 0 #@param {type:\"integer\"}\n","\n","# Если подвис ответ от GPT можно прервать обработку, установить row_first\n","# в значение на которой была прервана обработка и запустить обработку заново.\n","# Ранее обработанные вопросы будут сохранены в файле.\n","\n","# Обнуление общих затрат на групповой запрос.\n","total_price_query, total_token_query, total_query = 0, 0, 0\n","# Фиксация времени.\n","start_group = timeit.default_timer()\n","\n","for query in list_query[row_first-2:row_end-1]:\n","    # Проверка на пустой вопрс. Если пустой пропуск цикла.\n","    if not bool(query['question'].strip ()):\n","        print(f'На строке № {query[\"line\"]} - вопроса нет.')\n","        continue\n","    # Отправка запроса. Фиксация времени.\n","    start = timeit.default_timer()\n","    try:\n","        query[\"answer_gpt\"]= answer_index(\n","            model = SELECT_MODEL_GPT,\n","            system = federallab_chat_promt,\n","            topic = \"\",\n","            query = query,\n","            search_index = federallab_bd_index,\n","            temp = temperature,\n","            seed = 0,\n","            verbose_documents = 0,\n","            verbose_price = 0,\n","            top_documents = top_documents,\n","            limit_score = limit_score,\n","        )\n","        total_price_query += query['price_query']\n","        total_token_query += query['token_query']\n","        total_query +=1\n","    except Exception as e:\n","        print(f'Ошибка ответа GPT на строке №{query[\"line\"]}. - {e}')\n","    end = timeit.default_timer()\n","    # Сообщение об успешности ответа от GPT.\n","    print(f'Строка №{query[\"line\"]}. Ответ на вопрос получен за - {round(end-start, 3)} сек.')\n","\n","    # Запись ответа в файл.\n","    try:\n","        if bool(query['answer_gpt']):\n","            worksheet.update_cell(query['line'], 6, query['answer_gpt'])            # Ответ GPT.\n","            worksheet.update_cell(query['line'], 10, query['chank_1'])              # Чанк №1.\n","            worksheet.update_cell(query['line'], 11, query['chank_2'])              # Чанк №2.\n","            worksheet.update_cell(query['line'], 12, query['chank_3'])              # Чанк №3.\n","            worksheet.update_cell(query['line'], 13, query['seed'])                 # seed №3.\n","            worksheet.update_cell(query['line'], 14, query['system_fingerprint'])   # system_fingerprint.\n","            print(f'Строка №{query[\"line\"]}. Ответ записан в файл.')\n","            # Контроль номализации вопроса и перезапись его в таблице.\n","            if question_norma:\n","                question_old = worksheet.row_values(query['line'])[column_question]\n","                if not (question_old == query['question']):\n","                    print(\"    Вопрос нормализован и перезаписан в таблице.\")\n","                    print(f\"    Старый вариант: {question_old}\")\n","                    print(f\"    Новый вариант : {query['question']}\")\n","                    worksheet.update_cell(query['line'], column_question+1, query['question'])\n","    except Exception as e:\n","        print('\\n========================================================')\n","        print(f'!!!Ошибка записи строки №{query[\"line\"]} в файл. - {e}')\n","        print('========================================================')\n","\n","end_group = timeit.default_timer()\n","\n","# Вывод вопросов и ответов.\n","if verbose_answer:\n","    for i, query in enumerate(list_query):\n","        if query['answer_gpt']:\n","            print()\n","            print(insert_newlines(f\"ВОПРОС №{i+2}: {query['question']}\"))\n","            print('---------------------------')\n","            print(insert_newlines(f\"\\nОТВЕТ: {query['answer_gpt']}\"))\n","            print('===========================\\n')\n","            if verbose_chank:\n","                print(query['chank_1'])\n","                print()\n","                print(query['chank_2'])\n","                print()\n","                print(query['chank_3'])\n","\n","print()\n","print('-------------------------------------------')\n","print(f'Вопросов в пакетной обработке - {total_query} шт.')\n","print(f'Время пакетной обработки      - {round(end_group-start_group, 1)} сек.')\n","print(f'Стоимость пакетной обработки  - {round(total_price_query, 4)} $.')\n","print(f'Токенов в пакетной обработке  - {total_token_query} шт.')"],"metadata":{"id":"gUUdJGRRc1KJ","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703657298884,"user_tz":-420,"elapsed":15233,"user":{"displayName":"Andrey Petrunin","userId":"10287206466677589219"}},"outputId":"c06bb9a6-7b7d-463c-d6b8-00cd245f4bac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Строка №2. Ответ на вопрос получен за - 13.208 сек.\n","Строка №2. Ответ записан в файл.\n","\n","-------------------------------------------\n","Вопросов в пакетной обработке - 1 шт.\n","Время пакетной обработки      - 14.9 сек.\n","Стоимость пакетной обработки  - 0.0028 $.\n","Токенов в пакетной обработке  - 2571 шт.\n"]}]}]}