{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPuw7Sz3AWKkAI0Y15cwy6i"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c11307980de0430da4820422f1b32593":{"model_module":"@jupyter-widgets/controls","model_name":"GridBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"GridBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"GridBoxView","box_style":"","children":["IPY_MODEL_8224a3ebcc5a4e06b1c3997b74dc9e0e","IPY_MODEL_c32d080b01a4441ea0fac2f8441a8830","IPY_MODEL_bf4369be030a4c6385ec3af9a1848eef"],"layout":"IPY_MODEL_617c378960fb4d7297f96de3ce87b859"}},"8224a3ebcc5a4e06b1c3997b74dc9e0e":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_81152a9a7287408e8a93799c39df11a2","msg_id":"","outputs":[]}},"c32d080b01a4441ea0fac2f8441a8830":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_5bf8e0d90ecb4694b78b0c32c832ccd2","msg_id":"","outputs":[]}},"bf4369be030a4c6385ec3af9a1848eef":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_eaf149d98650442a87cbf5fcd74182cc","msg_id":"","outputs":[]}},"617c378960fb4d7297f96de3ce87b859":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":"\"left-sidebar center right-sidebar\"","grid_template_columns":"1fr 3fr 4fr","grid_template_rows":"3fr","height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81152a9a7287408e8a93799c39df11a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":"1px solid black","bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":"left-sidebar","grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":"auto","justify_content":null,"justify_items":null,"left":null,"margin":"3px","max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":"3px","right":null,"top":null,"visibility":null,"width":"50"}},"5bf8e0d90ecb4694b78b0c32c832ccd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":"1px solid black","bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":"right-sidebar","grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":"auto","justify_content":null,"justify_items":null,"left":null,"margin":"3px","max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":"3px","right":null,"top":null,"visibility":null,"width":"auto"}},"eaf149d98650442a87cbf5fcd74182cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":"1px solid black","bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":"center","grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":"auto","justify_content":null,"justify_items":null,"left":null,"margin":"3px","max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":"3px","right":null,"top":null,"visibility":null,"width":"auto"}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"cellView":"form","id":"5KzXaxam1GvH","executionInfo":{"status":"ok","timestamp":1703328183981,"user_tz":-420,"elapsed":64770,"user":{"displayName":"Andrey Petrunin","userId":"10287206466677589219"}}},"outputs":[],"source":["# @title Импорт библиотек\n","\n","# Фиксируем версии библиотек на 22.11.2023\n","!pip  install  tiktoken==0.5.1\n","!pip  install  langchain==0.0.339\n","!pip  install  openai==1.3.4\n","!pip  install  faiss-cpu==1.7.4\n","!pip install gspread==3.4.2\n","!pip install ipywidgets\n","# !pip install -q ipywidgets#==8.0.6\n","\n","from langchain.vectorstores import FAISS\n","from langchain.docstore.document import Document\n","from langchain.embeddings.openai import OpenAIEmbeddings\n","from langchain.text_splitter import MarkdownHeaderTextSplitter\n","\n","import requests\n","import os\n","import re\n","import getpass\n","import openai\n","import tiktoken\n","from openai import OpenAI\n","import zipfile\n","from IPython import display\n","import timeit\n","import time\n","from collections import Counter\n","import ipywidgets as widgets\n","# from ipywidgets import AppLayout, Button, Layout\n","\n","import gspread                  # Импортируем API для работы с Google таблицами\n","from google.colab import auth   # Импортируем модуль для аутентификации\n","from google.auth import default # Импортируем модуль для работы с учетными данными\n","\n","from ipywidgets import AppLayout, Button, Layout\n","from IPython import display\n","\n","# Очистить экран.\n","display.clear_output()\n","# print(widgets.__version__)"]},{"cell_type":"code","source":["# @title Главное окно.    Для обновления окна нужно выбрать эту ячейку и нажать - Ctrl+F10\n","\n","header_layout = widgets.Layout(width=\"auto\", height=\"auto\", border='1px solid black', padding='3px', margin='3px')\n","left_layout   = widgets.Layout(width=\"50\", height=\"auto\", border='1px solid black', padding='3px', margin='3px')\n","right_layout  = widgets.Layout(width=\"auto\", height=\"auto\", border='1px solid black', padding='3px', margin='3px')\n","center_layout = widgets.Layout(width=\"auto\", height=\"auto\", border='1px solid black', padding='3px', margin='3px')\n","footer_layout = widgets.Layout(width=\"auto\", height=\"auto\", border='1px solid black', padding='3px', margin='3px')\n","#left_layout.visibility = 'visible' # ['visible', 'hidden', 'inherit', 'initial', 'unset']\n","\n","\n","# output_style=dict(\n","#     font_style='italic',\n","#     font_weight='bold',\n","#     font_variant=\"small-caps\",\n","#     text_color='red',\n","#     text_decoration='underline'\n","# )\n","\n","\n","header = widgets.Output(layout=header_layout)\n","left = widgets.Output(layout=left_layout)\n","right = widgets.Output(layout=right_layout)\n","center = widgets.Output(layout=center_layout)\n","footer = widgets.Output(layout=footer_layout)\n","\n","App = widgets.AppLayout(header=None, left_sidebar=left, center=center, right_sidebar=right, footer=None,\n","        pane_widths=[1, 3, 4],\n","        # pane_heights=[1, 5, '60px']\n",")\n","\n","display.display(App)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":31,"referenced_widgets":["c11307980de0430da4820422f1b32593","8224a3ebcc5a4e06b1c3997b74dc9e0e","c32d080b01a4441ea0fac2f8441a8830","bf4369be030a4c6385ec3af9a1848eef","617c378960fb4d7297f96de3ce87b859","81152a9a7287408e8a93799c39df11a2","5bf8e0d90ecb4694b78b0c32c832ccd2","eaf149d98650442a87cbf5fcd74182cc"]},"cellView":"form","id":"nbL7fuHa2Aun","executionInfo":{"status":"ok","timestamp":1703328183983,"user_tz":-420,"elapsed":14,"user":{"displayName":"Andrey Petrunin","userId":"10287206466677589219"}},"outputId":"88e0dcb4-b5fb-4644-d208-8594526605a2"},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":["AppLayout(children=(Output(layout=Layout(border='1px solid black', grid_area='left-sidebar', height='auto', ma…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c11307980de0430da4820422f1b32593"}},"metadata":{}}]},{"cell_type":"markdown","source":["# Программа"],"metadata":{"id":"DSddUIq_6UwH"}},{"cell_type":"code","source":["#@title Вспомогательные функции\n","\n","def num_tokens_from_string(string: str) -> int:\n","    \"\"\"Возвращает количество токенов в строке\"\"\"\n","    # Выбор кодировщика. `cl100k_base`используется для `gpt-4`, `gpt-3.5-turbo`, `text-embedding-ada-002`\n","    encoding = tiktoken.get_encoding(\"cl100k_base\")\n","    # Разбивка строки на токены и подсчет из количества.\n","    num_tokens = len(encoding.encode(string))\n","    return num_tokens\n","\n","def split_text(text, verbose=0):\n","    \"\"\" Функция разбивает текст на чанки. \"\"\"\n","    # Шаблон MarkdownHeaderTextSplitter по которому будет делится переданный\n","    # текст в формате Markdown.\n","    headers_to_split_on = [ (\"#\",    \"Header 1\"),\n","                            (\"##\",   \"Header 2\"),\n","                            (\"###\",  \"Header 3\"),\n","                            (\"####\", \"Header 4\")\n","                        ]\n","    # Создаем экземпляр спилиттера.\n","    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n","    # Получаем список чанков.\n","    source_chunks = markdown_splitter.split_text(text)\n","\n","    # Обработка чанков.\n","    chank_count = len(source_chunks)\n","    chank_massage = \"\"\n","    for number, chank in enumerate(source_chunks):\n","        # Добавление информации в метаданные чанка о его номере в базе.\n","        chank.metadata[\"chank\"]=f'{number+1}/{chank_count}'\n","        # Вывод количества слов/токенов в фрагменте, если включен режим verbose.\n","        # if verbose:\n","        count = num_tokens_from_string(chank.page_content)\n","        chank_massage += f\"\\nChank#{number+1}/{chank_count}. Tokens in text = {count}\\n{'-' * 20}\\n{str(chank)}\\n{'=' * 20}\"\n","            # print(f\"\\n Chank#{number+1}/{chank_count}. Tokens in text = {count}\\n {'-' * 20}\\n{insert_newlines(str(chank))}\\n{'=' * 20}\")\n","\n","    # Возвращение списка фрагментов текста.\n","    return source_chunks, chank_massage\n","\n","def create_embedding(data, verbose=0):\n","    \"\"\"Функция преобразует текстовую Базу знаний в векторную.\"\"\"\n","    # Разбивка текста на чанки.\n","    source_chunks = []\n","    source_chunks,chank_massage = split_text(text=data, verbose=verbose)\n","\n","    # Создание векторной Базы знаний на основе чанков.\n","    search_index = FAISS.from_documents(source_chunks, OpenAIEmbeddings(), )\n","    # Подсчет общего количества токенов во всех чанках.\n","    count_token = num_tokens_from_string(' '.join([x.page_content for x in source_chunks]))\n","    # Печать сводной информации по созданию векторной Базы знаний.\n","    # print('\\n==================== ')\n","    # print('Количество токенов в документе :', count_token)\n","    # # Стоимость эмбэндинга согласно прайса на 22.11.2023 - 0,0001/1К токенов.\n","    # # https://openai.com/pricing#language-models\n","    # print('ЦЕНА запроса:', 0.0001*(count_token/1000), ' $')\n","    # print('==================== ')\n","    chank_massage=f\"Количество токенов в документе : {count_token}\\nЦЕНА запроса: {0.0001*(count_token/1000)} $\\n====================\"+chank_massage\n","    return search_index, chank_massage\n","\n","def load_file(url: str):\n","    \"\"\" Функция загрузки документа по url как текст.\"\"\"\n","    try:\n","        response = requests.get(url) # Получение документа по url.\n","        response.raise_for_status()  # Проверка ответа и если была ошибка - формирование исключения.\n","        return response.text\n","    except Exception as e:\n","        print(e)\n","\n","def load_search_indexes(url: str, verbose=0):\n","    \"\"\"Функция загружает текстовую Базу знаний и преобразует ее в векторную.\"\"\"\n","    try:\n","        return create_embedding(load_file(url), verbose=verbose)\n","    except Exception as e:\n","        print(e)\n","\n","def insert_newlines(text: str, max_len: int = 120) -> str:\n","    \"\"\" Функция форматирует переданный текст по длине\n","    для лучшего восприятия на экране.\"\"\"\n","    words = text.split()\n","    lines = []\n","    current_line = \"\"\n","    for word in words:\n","        if len(current_line + \" \" + word) > max_len:\n","            lines.append(current_line)\n","            current_line = \"\"\n","        current_line += \" \" + word\n","    lines.append(current_line)\n","    return \"\\n\".join(lines)\n","\n","# def filtred_docs (docs, limit_score):\n","#     \"\"\" Функция удаляет из отобранных чанков чанки у которых score выше значения limit_score.\n","#     При этом limit_score определяет гарантированно ошибочные чанки.\n","#     Далее отбор чанков идет в зависимости от значения score первого не нулевого\n","#     score. Если есть чанк с score=0 он оставляется единственным.\n","#     Если limit_score = 0, то чанки не фильтруются.\"\"\"\n","#     if bool(limit_score):\n","#         r = []\n","#         score = 0\n","#         def set_score(d, sc):\n","#             d[0].metadata[\"score\"]=sc\n","#             return d\n","#         for doc in docs:\n","#             s = doc[1]\n","#             if s==0:\n","#                 r.append( set_score(doc[0],s))\n","#                 break\n","#             if score==0:\n","#                 if s<.2:\n","#                     score = s*1.7\n","#                 elif s<.3:\n","#                     score = s +.05\n","#                 else:\n","#                     score = s +.01\n","#                 if score>limit_score:\n","#                         score = limit_score\n","#             if s<score:\n","#                     r.append(set_score(doc,s))\n","#         print(f'Фильр пропустил чанк(ов): {len(r)} из {len(docs)}')\n","#     else:\n","#         r = docs\n","#     return r\n","\n","def filtred_docs (docs, limit_score):\n","    \"\"\" Функция удаляет из отобранных чанков чанки у которых score выше значения limit_score.\"\"\"\n","    if bool(limit_score):\n","        r = []\n","        for doc in docs:\n","            if doc[1] <= limit_score:\n","                r.append(doc)\n","    else:\n","        r = docs\n","    return r\n","\n","def search_answers_maximum_repetition(list_answer):\n","    \"\"\" \"\"\"\n","    len_counter = Counter(len(i[\"answer\"]) for i in list_answer if \"answer\" in i)\n","    length_max = max(len_counter.values())\n","    key_max = [k for k, v in len_counter.items() if v == length_max][0]\n","    found_answer = [dict[\"answer\"] for dict in list_answer if len(dict[\"answer\"]) == key_max][0]\n","    return found_answer\n","\n","def answer_index(model, system, topic: str, query, search_index, temp = 0, seed = 1235, verbose_documents = 0,  verbose_price = 0, top_documents = 3, limit_score = 0.0):\n","    \"\"\" Основная функция которая формирует запрос и получает ответ от OpenAI по заданному вопросу\n","    на основе векторной Базы знаний. \"\"\"\n","\n","    # Выбор варианта вопроса. Если есть query, то вопрос задан из группового запроса и он имеет приоритет.\n","    question = query[\"question\"] if bool(query) else topic\n","    seed = query[\"seed\"] if bool(query) and not query.get('seed')==None else seed\n","    # Выборка релевантных чанков.\n","    docs = filtred_docs(search_index.similarity_search_with_score(question, k=top_documents), limit_score)\n","\n","    \"\"\" Этот блок закоментирован. Рассматривается возможность даполнительного\n","    запроса с фильтрацией чанков по метаданным. Пока нереализовано.\"\"\"\n","    # for i, doc in enumerate(docs):\n","    #     header1 = doc[0].metadata.get('Header 1')\n","    #     print(f'{i}. {header1}. Score: {doc[1]}')\n","    #     if header1=='Оценка' or header1=='Экспертиза':\n","    #         #docs = search_index.similarity_search_with_score(question, k=top_documents, )\n","    #         #print(f'{i}. {header1}. Score: {doc[1]}')\n","    #         pass\n","\n","\n","    message_content = \"\"            # Контекст для GPT.\n","    message_content_display = \"\"    # Контекст для вывода на экран.\n","    for i, doc in enumerate(docs):\n","        # Формирование контекста для запроса GPT и показа на экран отобранных чанков.\n","        message_content = message_content + f'Отрывок документа №{i+1}:{doc[0].page_content}'\n","        # message_content_display = message_content_display + f\"\\n Отрывок документа №{i+1}. Chank № {doc[0].metadata.get('chank')}. Score({doc[1]:.4f})\\n -----------------------\\n{insert_newlines(doc[0].page_content)}\\n\"\n","        message_content_display = message_content_display + f\"\\nОтрывок документа №{i+1}.  Chank № {doc[0].metadata.get('chank')}. Score({doc[1]:.4f})\\n{doc[0].page_content}\\n-----------------------\\n\"\n","\n","        # Сбор информации для группого запроса.\n","        if bool(query):\n","            # Выделение из строки метаданных ссылки. Если нет - присваиваем пустую строку.\n","            search_link_h1 = re.search(r'\\[(.*?)\\]', doc[0].metadata.get('Header 1')) if bool(doc[0].metadata.get('Header 1')) else \"\"\n","            search_link_h2 = re.search(r'\\[(.*?)\\]', doc[0].metadata.get('Header 2')) if bool(doc[0].metadata.get('Header 2')) else \"\"\n","            search_link_h3 = re.search(r'\\[(.*?)\\]', doc[0].metadata.get('Header 3')) if bool(doc[0].metadata.get('Header 3')) else \"\"\n","            search_link_h4 = re.search(r'\\[(.*?)\\]', doc[0].metadata.get('Header 4')) if bool(doc[0].metadata.get('Header 4')) else \"\"\n","            # Выбор самой внутренней ссылки. Если несколько ссылок, то самая внутренняя ссылается на расположение чанка на сайте.\n","            link = ''\n","            if bool(search_link_h4):\n","                link = search_link_h4.group(1)\n","            elif bool(search_link_h3):\n","                link = search_link_h3.group(1)\n","            elif bool(search_link_h2):\n","                link = search_link_h2.group(1)\n","            elif bool(search_link_h1):\n","                link = search_link_h1.group(1)\n","            # Заполнение запроса выбранными чанками.\n","            query[f\"chank_{i+1}\"] = f\"Chank № {doc[0].metadata.get('chank')}. Score({str(round(doc[1], 3))}).\\n{doc[0].page_content}.\\n--------\\n{link}\"\n","\n","    # Вывод на экран отобранных чанков.\n","    if (False): # verbose_documents\n","        print(message_content_display)\n","\n","    # Отправка запроса к Open AI.\n","    completion = OpenAI().chat.completions.create(\n","        model = model[0],\n","        messages = [\n","            {\"role\": \"system\", \"content\": system } ,\n","            {\"role\": \"user\", \"content\": f\"Документ с информацией для ответа пользователю : {message_content}.\\n\\nВопрос клиента: {question}\"}\n","        ],\n","        temperature=temp,\n","        seed = seed,\n","    )\n","\n","#======================================================================================\n","    # Подсчет токенов и стоимости.\n","    system_fingerprint = completion.system_fingerprint\n","    prompt_tokens = completion.usage.prompt_tokens\n","    total_tokens = completion.usage.total_tokens\n","    price_promt_tokens = prompt_tokens * model[1]/1000\n","    price_answer_tokens = (total_tokens - prompt_tokens) * model[2]/1000\n","    price_total_token = price_promt_tokens + price_answer_tokens\n","    # Сбор информации для группого запроса.\n","    if bool(query):\n","        query[\"price_query\"] = price_total_token\n","        query[\"price_question\"] = price_promt_tokens\n","        query[\"price_answer\"] = price_answer_tokens\n","        query[\"token_query\"] = total_tokens\n","        query[\"token_question\"] = prompt_tokens\n","        query[\"token_answer\"] = total_tokens - prompt_tokens\n","        query[\"system_fingerprint\"] = system_fingerprint\n","        query[\"seed\"] = seed\n","    # Вывод на экран стоимости запроса.\n","    message_price = f\"\\n=======================================================\\n{prompt_tokens} токенов использовано на вопрос. Цена: {price_promt_tokens:.6f} $.\\n{total_tokens - prompt_tokens} токенов использовано на ответ.  Цена: {price_answer_tokens:.6f} $.\\n{total_tokens} токенов использовано всего.     Цена: {price_total_token:.6f} $\\n======================================================= \\n\"\n","    if (False): #verbose_price\n","        print('\\n======================================================= ')\n","        print(f'{prompt_tokens} токенов использовано на вопрос. Цена: {round(price_promt_tokens, 6)} $.')\n","        print(f'{total_tokens - prompt_tokens} токенов использовано на ответ.  Цена: {round(price_answer_tokens, 6)} $.')\n","        print(f'{total_tokens} токенов использовано всего.     Цена: {round(price_total_token, 6)} $')\n","        print('======================================================= ')\n","        print(f\"seed = {seed}, system_fingerprint = {system_fingerprint}, len = {len(completion.choices[0].message.content)}\")\n","        print('======================================================= ')\n","\n","    # Ответ OpenAI.\n","    return completion.choices[0].message.content, message_content_display, message_price\n","\n","#======================================================================================\n","#question_normalization\n","def question_normalization(text):\n","    \"\"\" Функция нормализует текст вопроса. Удаляет лишние пробелы,\n","    символы, знаки. Делает первое слово с заглавной буквы.\"\"\"\n","\n","    # Удаление символов \"!?.,-\" из текста\n","    #text = re.sub(r'[-!?_]', '', text) # '[-!?.,_]'\n","    # Разделение текста на слова\n","    words = text.split()\n","    # # Проход по каждому слову\n","    # for i in range(len(words)):\n","    #     # Если слово состоит из заглавных букв и длина больше 1 символа, считаем это аббревиатурой\n","    #     if words[i].isupper() and len(words[i]) > 1:\n","    #         continue  # Пропускаем аббревиатуры\n","    #     else:\n","    #         words[i] = words[i].lower()  # Преобразуем в нижний регистр\n","    # # Преобразуем первое слово в строке к верхнему регистру\n","    #words[0] = words[0].capitalize()\n","    # Объединяем слова обратно в строку\n","    return ' '.join(words)\n","#======================================================================================\n","def load_bd_text(url: str, verbose=0):\n","    \"\"\" Функция загружает текстовую Базу знаний и\n","        преобразует ее в векторную.\"\"\"\n","    response = requests.get(url) # Получение документа по url.\n","    response.raise_for_status()  # Проверка ответа и если была ошибка - формирование исключения.\n","    return create_embedding(response.text, verbose=verbose)\n","#======================================================================================\n","def load_bd_vect(url: str, verbose=0):\n","    \"\"\" Функция загружает векторную Базу знаний.\"\"\"\n","    name_bd = 'federallab_bd_index.zip'\n","    # Скачивание архива Базы знаний\n","    response = requests.get(url) # Получение документа по url.\n","    response.raise_for_status()  # Проверка ответа и если была ошибка - формирование исключения.\n","    # Сохранение архива.\n","    with open(name_bd, 'wb') as file:\n","        file.write(response.content)\n","    # Разархивирование Базы знаний.\n","    with zipfile.ZipFile(name_bd, 'r') as zip:\n","        zip.extractall()\n","    # Загрузка векторной Базы знаний.\n","    federallab_bd = FAISS.load_local(f'federallab_bd_index', OpenAIEmbeddings())\n","\n","    # if verbose :\n","    docs = federallab_bd.similarity_search_with_score('', k=10000)\n","    docs_sorted = sorted(docs, key=lambda x: int(x[0].metadata.get('chank').split('/')[0]))\n","\n","    chank_massage = ''\n","    for doc in docs_sorted:\n","        count = num_tokens_from_string(doc[0].page_content)\n","        chank_massage += f\"\\nChank#{doc[0].metadata.get('chank')}. Tokens in text = {count}\\n{'-' * 20}\\n{str(doc)}\\n{'=' * 20}\"\n","\n","    return federallab_bd, chank_massage\n","#======================================================================================\n","def load_bd (url_vect: str, url_text: str, verbose=0):\n","    \"\"\" Функция организует очередность загрузки Базы знаний.\n","        Сначала идет загрузка векторной базы, если она не загружается,\n","        то загружается база в текстовом формате и потом преобразуется в векторную.\"\"\"\n","    try:\n","        federallab_bd = load_bd_vect(url_vect, verbose)\n","        print(\"Загрузка векторной Базы знаний выполнена успешно.\")\n","        return federallab_bd\n","    except Exception as e:\n","        print(\"По указанной ссылке векторной Базы знаний нет.\")\n","        print(e)\n","        print(\"\\nИдет загрузка текстовой Базы знаний...\")\n","        try:\n","            federallab_bd = load_bd_text(url_text, verbose)\n","            print(\"\\nЗагрузка текстовой Базы знаний выполнена успешно.\")\n","            return federallab_bd\n","        except Exception as e:\n","            print(\"\\nПо указанной ссылке текстовой Базы знаний нет.\")\n","            print(e)\n","            print(\"\\nОшибка загрузки!!\")\n","#======================================================================================\n","def load_bd_question(url: str):\n","    \"\"\" Функция загружает векторную Базу знаний.\"\"\"\n","    name_bd = 'federallab_bd_question.zip'\n","    # Скачивание архива Базы знаний\n","    response = requests.get(url) # Получение документа по url.\n","    response.raise_for_status()  # Проверка ответа и если была ошибка - формирование исключения.\n","    # Сохранение архива.\n","    with open(name_bd, 'wb') as file:\n","        file.write(response.content)\n","    # Разархивирование Базы знаний.\n","    with zipfile.ZipFile(name_bd, 'r') as zip:\n","        zip.extractall()\n","    # Загрузка векторной Базы знаний.\n","    federallab_bd = FAISS.load_local(f'federallab_bd_question', OpenAIEmbeddings())\n","    docs = federallab_bd.similarity_search_with_score('', k=10000)\n","    return_massege = f\"Вопрсов - {len(docs)} шт.\"\n","    return federallab_bd, return_massege"],"metadata":{"id":"wr9jQm4dvOeR","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Формирование оконного интерфейса и логики.\n","#======================================================================================\n","# Интерфейс.\n","#======================================================================================\n","# Левая боковая панель.\n","#======================================================================================\n","\"\"\"Блок формирования авторизации на OpenAI.\"\"\"\n","\n","width_link   = '305px'\n","width_button = '110px'\n","\n","label_api_key = widgets.Label(value = \"API key:\")\n","\n","api_key = widgets.Password(\n","    value='',\n","    placeholder='Введите OpenAi API key:',\n","    layout=Layout(width=width_link, height='28px'),)\n","\n","login_button = widgets.Button(\n","    description='Авторизация',\n","    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n","    layout=Layout(width=width_button, height='28px'),)\n","\n","def login_OpenAI():\n","    try:\n","        if api_key.value:\n","            login_button.button_style = 'info'\n","            login_button.description = \"...\"\n","            openai.api_key = api_key.value\n","            os.environ[\"OPENAI_API_KEY\"] = openai.api_key\n","            completion = OpenAI().chat.completions.create(\n","                model = 'gpt-3.5-turbo-1106',\n","                messages = [ {\"role\": \"system\", \"content\": \"\" }, {\"role\": \"user\", \"content\": \"\"}]\n","            )\n","            label_api_key.value = \"API key:   Авторизованы.\"\n","            login_button.button_style = 'success'\n","            login_button.description = \"OK!\"\n","        else:\n","            label_api_key.value = \"API key:   ВВЕДИТЕ КЛЮЧ!\"\n","            login_button.button_style = 'warning'\n","            login_button.button_style = ''\n","            login_button.description = \"Авторизация\"\n","    except Exception as e:\n","            label_api_key.value = \"API key:   НЕВЕРНЫЙ КЛЮЧ!\"\n","            login_button.button_style = 'warning'\n","            login_button.button_style = ''\n","            login_button.description = \"Авторизация\"\n","\n","def on_submit_api_key(api_key): login_OpenAI()\n","\n","def on_click_login(login_button): login_OpenAI()\n","\n","api_key.on_submit(on_submit_api_key)\n","\n","login_button.on_click(on_click_login)\n","\n","#========================================================================\n","\"\"\"Блок загрузки типовых вопросов.\"\"\"\n","\n","label_db_question = widgets.Label(value = \"База данных типовых вопросов:\")\n","\n","link_bd_question = widgets.Text(\n","    value='https://github.com/terrainternship/GPT_labsud/raw/main/federallab_bd_question.zip',\n","    layout=Layout(width=width_link, height='28px'),\n",")\n","\n","button_load_db_question = widgets.Button(\n","    description='Загрузить',\n","    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n","    layout=Layout(width=width_button, height='28px'),\n",")\n","\n","def on_button_clicked_load_db_question(button_load):\n","    try:\n","        button_load_db_question.description = 'Загрузка...'\n","        button_load_db_question.button_style = 'info'\n","        if not link_bd_question.value==None:\n","            global federallab_db_question\n","            federallab_db_question, return_masseges = load_bd_question(link_bd_question.value)\n","            label_db_question.value = f\"База данных типовых вопросов: {return_masseges}\"\n","            button_load_db_question.button_style = 'success'\n","            button_load_db_question.description = \"OK!\"\n","        else:\n","            label_db_question.value = f\"База данных типовых вопросов:   ВВЕДИТЕ ССЫЛКУ!\"\n","            button_load_db_question.button_style = 'warning'\n","            button_load_db_question.description = 'Загрузить'\n","            button_load_db_question.button_style = ''\n","    except Exception as e:\n","        label_db_question.value = f\"База данных типовых вопросов:   ПРОВЕРЬТЕ ССЫЛКУ!\"\n","        button_load_db_question.button_style = 'warning'\n","        button_load_db_question.description = 'Загрузить'\n","        button_load_db_question.button_style = ''\n","\n","button_load_db_question.on_click(on_button_clicked_load_db_question)\n","#========================================================================\n","\n","label_db_text   = widgets.Label(value = \"База знаний текстовая:\")\n","label_db_vector = widgets.Label(value = \"База знаний векторная:\")\n","\n","link_bd_text = widgets.Text(\n","    value='https://raw.githubusercontent.com/terrainternship/GPT_labsud/main/Datadase/LabSudDB_v1.md',\n","    layout=Layout(width=width_link, height='28px'),)\n","\n","link_bd_vector = widgets.Text(\n","    value='https://github.com/terrainternship/GPT_labsud/raw/main/federallab_bd_index_v2.zip',\n","    layout=Layout(width=width_link, height='28px'),)\n","\n","button_load_db_text = widgets.Button(\n","    description='Загрузить',\n","    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n","    layout=Layout(width=width_button, height='28px'),)\n","\n","button_load_db_vector = widgets.Button(\n","    description='Загрузить',\n","    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n","    layout=Layout(width=width_button, height='28px'),)\n","\n","federallab_db_string = ''\n","\n","def on_button_clicked_load_db_text(button_load):\n","    try:\n","        button_load_db_text.button_style = 'info'\n","        button_load_db_text.description = 'Загрузка...'\n","        if button_load_db_vector.description=='OK!':\n","            button_load_db_vector.description = 'Загрузить'\n","            button_load_db_vector.button_style = ''\n","            label_db_vector.value = \"База знаний векторная:\"\n","        global federallab_db, federallab_db_string\n","        federallab_db, federallab_db_string = load_bd_text(link_bd_text.value)\n","        button_load_db_text.button_style = 'success'\n","        button_load_db_text.description = 'OK!'\n","        label_db_text.value = \"База знаний текстовая: Загружена.\"\n","    except Exception as e:\n","        button_load_db_text.button_style = 'warning'\n","        button_load_db_text.description = 'Загрузить'\n","        label_db_text.value = \"База знаний текстовая: ПРОВЕРТЕ ССЫЛКУ!.\"\n","\n","def on_button_clicked_load_db_vector(button_load):\n","    try:\n","        button_load_db_vector.button_style = 'info'\n","        button_load_db_vector.description = 'Загрузка...'\n","        if button_load_db_text.description=='OK!':\n","            button_load_db_text.description = 'Загрузить'\n","            button_load_db_text.button_style = ''\n","            label_db_text.value = \"База знаний текстовая:\"\n","        global federallab_db, federallab_db_string\n","        federallab_db, federallab_db_string  = load_bd_vect(link_bd_vector.value)\n","        button_load_db_vector.button_style = 'success'\n","        button_load_db_vector.description = 'OK!'\n","        label_db_vector.value = \"База знаний векторная: Загружена.\"\n","    except Exception as e:\n","        button_load_db_vector.button_style = 'warning'\n","        button_load_db_vector.description = 'Загрузить'\n","        label_db_vector.value = \"База знаний векторная: ПРОВЕРТЕ ССЫЛКУ!.\"\n","\n","button_load_db_text.on_click(on_button_clicked_load_db_text)\n","button_load_db_vector.on_click(on_button_clicked_load_db_vector)\n","\n","button_load_all = widgets.Button(\n","    description='ВСЕ!',\n","    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n","    layout=Layout(width=width_button, height='28px', padding='0px 0px 0px 0px'),)\n","    # layout=Layout(width='130px', height='28px'),)\n","\n","\n","def on_button_clicked__load_all(button_load):\n","    on_button_clicked_load_db_question (button_load)\n","    on_button_clicked_load_db_vector(button_load)\n","    on_button_clicked_load_prom(button_load)\n","\n","button_load_all.on_click(on_button_clicked__load_all)\n","\n","#========================================================================\n","\n","label_load_data   = widgets.Label(value = \"Данные для загрузки\",               layout=Layout(width='90%', height='45px', padding='20px 0px 0px 0px'))\n","label_param_name  = widgets.Label(value = \"Параметры нейро-консультанта\",      layout=Layout(width='90%', height='45px', padding='15px 0px 0px 0px'))\n","label_param_cache = widgets.Label(value = \"Параметры отбора вопросов из кэша\", layout=Layout(width='90%', height='45px', padding='15px 0px 0px 0px'))\n","#========================================================================\n","\n","label_promt = widgets.Label(value = \"Инструкция нейро-консультанта:\")\n","\n","link_promt = widgets.Text(\n","    value='https://raw.githubusercontent.com/terrainternship/GPT_labsud/main/Galina/FLSE_promt',\n","    layout=Layout(width=width_link, height='28px'))\n","\n","button_load_promt = widgets.Button(\n","    description='Загрузить',\n","    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n","    layout=Layout(width=width_button, height='28px'))\n","\n","promt_federallab = ''\n","\n","def on_button_clicked_load_prom(button_load):\n","    try:\n","        button_load_promt.description = 'Загрузка...'\n","        button_load_promt.button_style = 'info'\n","        global promt_federallab\n","        promt_federallab = load_file(link_promt.value)\n","        button_load_promt.description = 'OK!'\n","        button_load_promt.button_style = 'success'\n","        label_promt.value = \"Инструкция нейро-консультанта: Загружена.\"\n","    except Exception as e:\n","        button_load_promt.description = 'Загрузка'\n","        button_load_promt.button_style = 'warning'\n","        label_promt.value = \"Инструкция нейро-консультанта: ПРОВЕРЬТЕ ССЫЛКУ!\"\n","\n","button_load_promt.on_click(on_button_clicked_load_prom)\n","#========================================================================\n","# Псевдоним = ['Имя модели', 'Цена токена - вопроса', 'Цена токена - ответа'].\n","MODEL_GPT_4_1106_PREVIEW = ['gpt-4-1106-preview', 0.01, 0.03]   # 128K tokens\n","MODEL_GPT_3_5_TURBO_1106 = ['gpt-3.5-turbo-1106', 0.001, 0.002] #  16K tokens\n","\n","SELECT_MODEL_GPT = MODEL_GPT_3_5_TURBO_1106\n","\n","model_gpt = widgets.Dropdown(\n","    options=[('gpt-3.5-turbo-1106', 1), ('gpt-4-1106-preview', 2)],\n","    value=1,\n","    description='Модель GPT OpenAI:     ',\n","    style = {'description_width': 'initial'},\n","    layout=Layout(width='99%', height='28px'))\n","\n","def on_change_value_model(change):\n","    global SELECT_MODEL_GPT\n","    if change['new'] == 1: SELECT_MODEL_GPT = MODEL_GPT_3_5_TURBO_1106\n","    if change['new'] == 2: SELECT_MODEL_GPT = MODEL_GPT_4_1106_PREVIEW\n","\n","model_gpt.observe(on_change_value_model, names='value')\n","#========================================================================\n","temperature = 0.0\n","\n","temperature_gpt = widgets.FloatSlider(\n","    value=temperature,\n","    min=0,\n","    max=2.0,\n","    step=0.05,\n","    description='Вариативность ответа:',\n","    continuous_update=False,\n","    orientation='horizontal',\n","    readout=True,\n","    readout_format='.2f',\n","    style = {'description_width': 'initial'},\n","    layout=Layout(width='99%', height='28px'),)\n","\n","def on_change_value_temperature(change):\n","    global temperature\n","    temperature = change['new']\n","\n","temperature_gpt.observe(on_change_value_temperature, names='value')\n","\n","#========================================================================\n","chank_threshold = 0.5\n","\n","input_chank_threshold = widgets.FloatSlider(\n","    value=chank_threshold, min=0, max=1.0, step=0.01,\n","    description='Порог отбора чанков:',\n","    continuous_update=False,\n","    orientation='horizontal',\n","    readout=True,  readout_format='.2f',\n","    style = {'description_width': 'initial'},\n","    layout=Layout(width='99%', height='28px'),)\n","\n","def on_change_value_chank_threshold(change):\n","    global chank_threshold\n","    chank_threshold = change['new']\n","\n","input_chank_threshold.observe(on_change_value_chank_threshold, names='value')\n","\n","#========================================================================\n","seed = 1235\n","\n","seed_gpt = widgets.IntText(\n","    value=seed,\n","    description='Повторяемость ответа:',\n","    style = {'description_width': 'initial'},\n","    layout=Layout(width='210px', height='28px'),)\n","\n","def on_change_value_seed(change): seed = change['new']\n","\n","seed_gpt.observe(on_change_value_seed, names='value')\n","\n","#========================================================================\n","top_documents = 3\n","\n","input_top_documents = widgets.IntText(\n","    value = top_documents,\n","    description = 'Количество чанков:',\n","    style = {'description_width': 'initial'},\n","    layout = Layout(width='170px', height='28px'),)\n","\n","def on_change_value_top_documents(change):\n","     global top_documents\n","     top_documents = change['new']\n","\n","input_top_documents.observe(on_change_value_top_documents, names='value')\n","\n","#========================================================================\n","question_norma = True\n","\n","input_question_norma = widgets.Checkbox(\n","    value = question_norma,\n","    description = 'Нормализация вопроса',\n","    style = {'description_width': 'initial'},\n","    layout=Layout(width='90%', height='28px'),)\n","\n","def on_change_value_question_norma(change):\n","    global question_norma\n","    question_norma = change['new']\n","\n","input_question_norma.observe(on_change_value_question_norma, names='value')\n","\n","#========================================================================\n","verbose_chank = True\n","\n","input_verbose_chank = widgets.Checkbox(\n","    value = verbose_chank,\n","    description = 'Показать чанки',\n","    style = {'description_width': 'initial'},\n","    layout=Layout(width='90%', height='28px'),)\n","\n","def on_change_value_verbose_chank(change):\n","    global verbose_chank\n","    verbose_chank = change['new']\n","\n","input_verbose_chank.observe(on_change_value_verbose_chank, names='value')\n","\n","#========================================================================\n","verbose_price = True\n","\n","input_verbose_price = widgets.Checkbox(\n","    value = verbose_price,\n","    description = 'Показать стоимость ответа',\n","    style = {'description_width': 'initial'},\n","    layout=Layout(width='90%', height='28px'),)\n","\n","def on_change_value_verbose_price(change):\n","    global verbose_price\n","    verbose_price = change['new']\n","\n","input_verbose_price.observe(on_change_value_verbose_price, names='value')\n","\n","#========================================================================\n","cache_number = 15\n","\n","input_cache_number = widgets.IntSlider(\n","    value=cache_number, min=1, max=20, step=1,\n","    description='Максимальное число вопросов:',\n","    continuous_update=False,\n","    orientation='horizontal',\n","    readout=True,\n","    # readout_format='2f',\n","    style = {'description_width': 'initial'},\n","    layout=Layout(width='99%', height='28px'),)\n","\n","def on_change_value_cache_number(change):\n","    print(change['new'])\n","    global cache_number\n","    cache_number = change['new']\n","    change_value_question_client()\n","\n","input_cache_number.observe(on_change_value_cache_number, names='value')\n","\n","#========================================================================\n","cache_threshold = 0.5\n","\n","input_cache_threshold = widgets.FloatSlider(\n","    value=cache_threshold, min=0, max=1.0, step=0.01,\n","    description='Порог отбора вопросов:',\n","    continuous_update=False,\n","    orientation='horizontal',\n","    readout=True,  readout_format='.2f',\n","    style = {'description_width': 'initial'},\n","    layout=Layout(width='99%', height='28px'),)\n","\n","def on_change_value_cache_threshold(change):\n","    global cache_threshold\n","    cache_threshold = change['new']\n","    change_value_question_client()\n","\n","input_cache_threshold.observe(on_change_value_cache_threshold, names='value')\n","\n","#========================================================================\n","#========================================================================\n","output_dialogs = widgets.Textarea(\n","    value='',\n","    layout=Layout(width='99.5%', height='500px'),\n","    continuous_update = True,\n",")\n","\n","#========================================================================\n","\n","input_qestion_from_cache = widgets.Select(\n","    options=[('        Список вопросов из кэша.', 0)],\n","    value=0,\n","    rows=cache_number+1,\n","    layout=Layout(width='99.5%', height='auto'),\n",")\n","\n","\n","def on_change_value_qestion_from_cache(change):\n","    if not not change['new']:\n","        output_dialogs.value = f\"Клиент:\\n    {docs[change['new']-1][0].page_content} \\n----------\\nМенеджер (кэш):\\n    {docs[change['new']-1][0].metadata['answer_gpt']}\\n==========\\n\\n{output_dialogs.value}\"\n","    global gpt_chank, gpt_price\n","    gpt_chank, gpt_price = '',''\n","    output_textarea_info(promt_federallab, gpt_chank, gpt_price, federallab_db_string)\n","\n","input_qestion_from_cache.observe(on_change_value_qestion_from_cache, names='value')\n","#========================================================================\n","\n","input_question_client = widgets.Text(\n","    value='',\n","    placeholder='Введите вопрос.',\n","    layout=Layout(width='99.5%', height='28px'),\n","    # description='String:',\n","    disabled=False,)\n","\n","button_sent_question = widgets.Button(\n","    description='>',\n","    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n","    layout=Layout(width='28px', height='28px'),\n",")\n","#===================================================================================================\n","gpt_answer = ''\n","gpt_chank = ''\n","gpt_price = ''\n","\n","def sent_question(model, system, topic: str, query, search_index, temp = 0, seed = 1235, verbose_documents = 0,  verbose_price = 0, top_documents = 3, limit_score = 0.0):\n","    start_group = timeit.default_timer()\n","\n","    # Нормализация вопроса при необходимости.\n","    question = question_normalization(input_question_client.value) if question_norma else input_question_client.value\n","    # Запрос GPT\n","    global gpt_answer, gpt_chank, gpt_price\n","    gpt_answer, gpt_chank, gpt_price = answer_index(\n","        model = SELECT_MODEL_GPT,\n","        system = system,\n","        topic = topic,\n","        query = '',\n","        search_index = federallab_db,\n","        temp = temp,\n","        seed = seed,\n","        verbose_documents = verbose_chank,\n","        verbose_price = verbose_price,\n","        top_documents = top_documents,\n","        limit_score = chank_threshold,)\n","\n","    stop_group = timeit.default_timer()\n","\n","    output_dialogs.value = f\"Клиент:\\n    {topic} \\n----------\\nМенеджер ({stop_group-start_group:.2f} сек.):\\n    {gpt_answer}\\n==========\\n\\n{output_dialogs.value}\"\n","    output_textarea_info(promt_federallab, gpt_chank, gpt_price, federallab_db_string)\n","#===================================================================================================\n","#==========================+++++++++++++++++++++++++++++++++++++++++++===============================\n","def change_value_question_client():\n","    input_qestion_from_cache.options = []\n","    qestion_from_cache = [('        Список вопросов из кэша.', 0)]\n","    if input_question_client.value:\n","        global docs\n","        docs = filtred_docs(federallab_db_question.similarity_search_with_score(input_question_client.value, k=cache_number), cache_threshold)\n","        for i, doc in enumerate(docs):\n","            if not doc[0].page_content == None:\n","                qestion_from_cache.append((f\" #{i+1:02}. (Score: {doc[1]:.4f}).  Вопрос: {doc[0].page_content} \", i+1))\n","    input_qestion_from_cache.options = qestion_from_cache\n","\n","\n","def on_change_value_question_client(change):\n","    change_value_question_client()\n","\n","def on_click_button_sent_question(change):\n","\n","    if not login_button.description == 'OK!':\n","        print('Введите ключ API OpenAI!')\n","        return\n","    if not button_load_db_vector.description == 'OK!' and not button_load_db_text.description == 'OK!' :\n","        print('Загрузите Базу знаний!')\n","        return\n","    if not button_load_promt.description == 'OK!':\n","        print('Загрузите промт!')\n","        return\n","\n","    button_sent_question.button_style = 'success'\n","    button_sent_question.description = '..'\n","\n","    sent_question(\n","        model = SELECT_MODEL_GPT,\n","        system = promt_federallab,\n","        topic = input_question_client.value,\n","        query = '',\n","        search_index = federallab_db,\n","        temp = temperature,\n","        seed = seed,\n","        verbose_documents = verbose_chank,\n","        verbose_price = verbose_price,\n","        top_documents = top_documents,\n","        limit_score = chank_threshold,)\n","\n","    button_sent_question.button_style = 'info'\n","    button_sent_question.description = '>'\n","\n","input_question_client.observe(on_change_value_question_client, names='value')\n","input_question_client.on_submit(on_click_button_sent_question)\n","button_sent_question.on_click(on_click_button_sent_question)\n","#===================================================================================================\n","#===================================================================================================\n","button_info = widgets.ToggleButtons(\n","    options=['Чанки', 'Все чанки', 'Промт'],\n","    value = 'Чанки',\n","    # description='Speed:',\n","    disabled=False,\n","    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n","    # tooltips=['Description of slow', 'Description of regular', 'Description of fast'],\n","    icons=['check'] * 3\n",")\n","\n","def output_textarea_info(promt_federallab, gpt_chank, gpt_price, federallab_db_string ):\n","    page = button_info.value\n","    Textarea_info.value = ''\n","    if page == 'Промт':\n","        Textarea_info.value = promt_federallab\n","    elif page == 'Чанки':\n","       Textarea_info.value = gpt_chank + gpt_price\n","    elif page == 'Все чанки':\n","        Textarea_info.value = federallab_db_string\n","\n","def on_change_value_button_info(change):\n","    output_textarea_info(promt_federallab, gpt_chank, gpt_price, federallab_db_string)\n","\n","\n","button_info.observe(on_change_value_button_info, names='value')\n","\n","Textarea_info   = widgets.Textarea(\n","    value='',\n","    layout=Layout(width='99.5%', height='780px'),)\n"],"metadata":{"id":"HqDibvk8zDPL","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Вывод на экран оконного интерфеса\n","form_item_layout = Layout(display='flex', flex_flow='row', justify_content='space-between',  ) #border='1px solid black'\n","dialog_layout = Layout(display='flex', justify_content='flex-end', align_items = 'stretch' ) #, flex_flow='column' , flex-direction = 'column-reverse'\n","\n","display.clear_output()\n","header.clear_output()\n","left.clear_output()\n","center.clear_output()\n","\n","# with header:\n","#     display.display(image_flse)  button_load_all\n","with left:\n","    display.display(widgets.VBox([label_api_key,\n","                                  widgets.HBox([api_key, login_button], layout=form_item_layout),\n","                                  label_load_data,\n","                                  widgets.HBox([label_db_question, button_load_all], layout=form_item_layout),\n","                                  widgets.HBox([link_bd_question, button_load_db_question], layout=form_item_layout),\n","                                  label_db_text,\n","                                  widgets.HBox([link_bd_text, button_load_db_text], layout=form_item_layout),\n","                                  label_db_vector,\n","                                  widgets.HBox([link_bd_vector, button_load_db_vector], layout=form_item_layout),\n","                                  label_promt,\n","                                  widgets.HBox([link_promt, button_load_promt], layout=form_item_layout),\n","                                  label_param_name,\n","                                  model_gpt,\n","                                  temperature_gpt,\n","                                  input_chank_threshold,\n","                                  widgets.HBox([input_top_documents, seed_gpt], layout=form_item_layout),\n","                                  input_question_norma,\n","                                  input_verbose_chank,\n","                                  input_verbose_price,\n","                                  label_param_cache,\n","                                  input_cache_threshold,\n","                                  input_cache_number,\n","                                ]))\n","with center:\n","    display.display(widgets.VBox([output_dialogs,\n","                                  widgets.HBox([input_question_client,button_sent_question],layout=form_item_layout),\n","                                  input_qestion_from_cache,\n","                                ], layout = dialog_layout))\n","with right:\n","    display.display(button_info,\n","                    Textarea_info,\n","    )\n","# with footer:\n","#     print(\"This is output widget\")"],"metadata":{"id":"uwZNB_SDRBgr","cellView":"form"},"execution_count":null,"outputs":[]}]}